{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "rgn2_play.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMCCozHZ4MhRpJY40idz1IE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hushuangwei/rgn2-replica/blob/main/rgn2_play.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y-jmJk5S5sG"
      },
      "source": [
        "* How would coevolution implicitly affect the language model training?\n",
        "* Would kNN-style unsupervised learning useful for RGN2?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "bisOhBV5FBxp",
        "outputId": "9a869ace-a3ff-4b40-9d8d-46b80077c364"
      },
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\"); \n",
        "     btn.click() \n",
        "     }\n",
        "   \n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\"); \n",
        "     btn.click() \n",
        "     }\n",
        "  }\n",
        "  \n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              " function ClickConnect(){\n",
              "   btn = document.querySelector(\"colab-connect-button\")\n",
              "   if (btn != null){\n",
              "     console.log(\"Click colab-connect-button\"); \n",
              "     btn.click() \n",
              "     }\n",
              "   \n",
              "   btn = document.getElementById('ok')\n",
              "   if (btn != null){\n",
              "     console.log(\"Click reconnect\"); \n",
              "     btn.click() \n",
              "     }\n",
              "  }\n",
              "  \n",
              "setInterval(ClickConnect,60000)\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO2-ZpV7SuFi"
      },
      "source": [
        "!git clone https://github.com/hushuangwei/rgn2-replica.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS7DR2x_9kV_"
      },
      "source": [
        "# https://blog.csdn.net/NEUdeep/article/details/115724826\n",
        "!export PYTHONWARNINGS='ignore:semaphore_tracker:UserWarning'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4w9hFGdUZmc"
      },
      "source": [
        "!pip install wandb sidechainnet einops proDy tqdm datasets transformers x-transformers pytorch-lightning fair-esm En-transformer pytorch3d invariant_point_attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYVrT9vEBthE",
        "outputId": "80e40f7b-ad1c-44a5-eab9-95abb1049203"
      },
      "source": [
        "%cd rgn2-replica/scripts/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/rgn2-replica/scripts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6kBnPjeMxMw"
      },
      "source": [
        "One can skip this google drive setting and download sidechainnet data directly but more slowly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUVr-8p-at6T",
        "outputId": "d11f57da-bae4-44a9-a6e8-6c0050e2a9f6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKeXyuo6Z4-o"
      },
      "source": [
        "!mkdir -p /content/rgn2-replica/scripts/sidechainnet_data/\n",
        "!cp /content/drive/MyDrive/protein/sidechainnet_casp12_90.pkl /content/rgn2-replica/scripts/sidechainnet_data/"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0JBGC4vHYe-",
        "outputId": "eb9e3478-925d-4402-fa82-4a136d5da534"
      },
      "source": [
        "!wandb login"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8z-qNqGTlVh"
      },
      "source": [
        "!nohup python train_rgn2.py --device cuda:0 --wb_entity hushuangwei \\\n",
        "   --wb_proj rgn2_replica --run_name RGN2_ipa_1e-4 \\\n",
        "   --min_len_valid 50 --casp_version 12 --scn_thinning 90 \\\n",
        "   --min_len 0 --max_len 384 --input_dropout 0.1 --num_layers 6 \\\n",
        "   --bidirectional 1 --layer_type LSTM --act aconc --num_recycles_train 8 \\\n",
        "   --refiner_args \"{\\\"refiner_type\\\": \\\"IPA\\\"}\" \\\n",
        "   > RGN2X_vanillaLSTM_full_run_logs.txt 2>&1 &"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh2vtuZ-Uc72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9cb8a21-b6ca-47fb-c657-dd7b676d5242"
      },
      "source": [
        "!tail -f RGN2X_vanillaLSTM_full_run_logs.txt"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wandb:            loss 0.08731\n",
            "wandb:            rmsd 9.9361\n",
            "wandb:    torsion_loss 1.76916\n",
            "wandb:       viol_loss 0.00342\n",
            "wandb: \n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "wandb: Synced RGN2_ipa_1e-4: https://wandb.ai/hushuangwei/rgn2_replica/runs/372ib897\n",
            "wandb: Find logs at: ./wandb/run-20211010_110523-372ib897/logs/debug.log\n",
            "wandb: \n",
            "\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tNr33PMAsiy"
      },
      "source": [
        "!pkill -f train_rgn2.py"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGrjhdZB0crD",
        "outputId": "5088c897-2ef1-48d8-cb01-87926a6a9d8d"
      },
      "source": [
        "!ps aux | grep train_rgn2.py"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root        2285  0.0  0.0  39200  6252 ?        S    12:47   0:00 /bin/bash -c ps aux | grep train_rgn2.py\n",
            "root        2287  0.0  0.0  38572  5180 ?        S    12:47   0:00 grep train_rgn2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa2fwnskPqRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71e4390e-08bd-4348-d82c-cb45cba91408"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct  5 08:13:04 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P0   103W / 300W |  11293MiB / 16160MiB |     59%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlgXayRhMa0v"
      },
      "source": [
        "# below is unfinished"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWV02qQUNvFO"
      },
      "source": [
        "import sidechainnet as scn\n",
        "import random \n",
        "\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "import torch\n",
        "import py3Dmol\n",
        "import esm\n",
        "\n",
        "from rgn2_replica import *\n",
        "from rgn2_replica.rgn2 import *\n",
        "from rgn2_replica.rgn2_utils import *\n",
        "from rgn2_replica.rgn2_trainers import *"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o04uJC6CVZFi"
      },
      "source": [
        "from sidechainnet.utils.sequence import ProteinVocabulary as VOCAB\n",
        "VOCAB = VOCAB()"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-y5nsoxwZSM",
        "outputId": "67a7536a-a23d-4f37-9492-43d1c6f7d7ae"
      },
      "source": [
        "set_seed(42)\n",
        "dataloaders = scn.load(casp_version=12, thinning=90, with_pytorch=\"dataloaders\", \n",
        "                                batch_size=1, dynamic_batching=False)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SidechainNet was loaded from ./sidechainnet_data/sidechainnet_casp12_90.pkl.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfTlIEmgK1C4"
      },
      "source": [
        "# if torch.cuda.is_available():\n",
        "#     device = torch.device(\"cuda\")\n",
        "# else:\n",
        "#     device = torch.device(\"cpu\")\n",
        "device = \"cpu\"\n",
        "model =  RGN2_IPA(embedding_dim=1284).to(device)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkgieANeMKe_",
        "outputId": "42073236-ac77-4284-9fcc-6d00d21fc002"
      },
      "source": [
        "save_path = \"/content/rgn2-replica/scripts/rgn2_models/RGN2_ipa_1e-4@_32K.pt\"\n",
        "model.load_state_dict(torch.load(save_path))\n",
        "sum([p.numel() for p in model.parameters()])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34216661"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgJDm6ohv0FO"
      },
      "source": [
        "dataloaders[\"train\"].dataset\n",
        "MIN_LEN_TEST = 70\n",
        "MIN_LEN = 0\n",
        "MAX_LEN = 512"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjWn3Q3vOrtt"
      },
      "source": [
        "embedder, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
        "batch_converter = alphabet.get_batch_converter()"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD28yPldv-xi"
      },
      "source": [
        "embedder = embedder.to(device)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "0fICN-VLUwEq",
        "outputId": "d91ecc41-92e2-4b99-d3b6-04aca1bb2b40"
      },
      "source": [
        "### TEST\n",
        "tic = time.time()\n",
        "get_prot_test_ = mp_nerf.utils.get_prot( \n",
        "    dataloader_=dataloaders, \n",
        "    vocab_=VOCAB, # mp_nerf.utils.\n",
        "    min_len=MIN_LEN, max_len=MAX_LEN, \n",
        "    verbose=False, subset=\"test\"\n",
        ")\n",
        "# get num of unique, full-masked proteins\n",
        "seqs = []\n",
        "for i, prot_args in enumerate(dataloaders[\"test\"].dataset):\n",
        "    # (id, int_seq, mask, ... , str_seq)\n",
        "    length = len(prot_args[-1]) \n",
        "    if 0 < length < MAX_LEN and sum( prot_args[2] ) == length:\n",
        "        seqs.append( prot_args[-1] )\n",
        "\n",
        "metrics_stuff_test = predict(\n",
        "    get_prot_= get_prot_test_, \n",
        "    steps = len(set(seqs)), # 24 for MIN_LEN=70\n",
        "    model = model,\n",
        "    embedder = embedder, \n",
        "    return_preds = True,\n",
        "    log_every = 4,\n",
        "    accumulate_every = len(set(seqs)),\n",
        "    seed = 42, # 42\n",
        "    mode = \"fast_test\", # \"test\" # \"test\" is for AR, \"fast_test\" is for iterative\n",
        "    recycle_func = lambda x: 1, # 5 # 3 # 2 \n",
        "    wandbai = False,\n",
        ")\n",
        "preds_list_test, metrics_list_test, metrics_stats_test = metrics_stuff_test\n",
        "print(\"\\n\", \"Test Results:\", sep=\"\")\n",
        "for k,v in metrics_stats_test.items():\n",
        "    offset = \" \" * ( max(len(ki) for ki in metrics_stats_test.keys()) - len(k) )\n",
        "    print(k + offset, \":\", v)\n",
        "print(\"\\n\")\n",
        "print(\"Time taken: \", time.time()-tic, \"\\n\")"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 246, 2])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-ef6f4774afe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"fast_test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# \"test\" # \"test\" is for AR, \"fast_test\" is for iterative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mrecycle_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 5 # 3 # 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mwandbai\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[0mpreds_list_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_list_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_stats_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics_stuff_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/rgn2-replica/rgn2_replica/rgn2_trainers.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(get_prot_, steps, model, embedder, return_preds, accumulate_every, log_every, seed, wandbai, recycle_func, mode)\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0mprots\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecycle_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecycle_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m             )\n\u001b[1;32m    337\u001b[0m         \u001b[0;31m# calculate metrics || calc loss terms || baselines for next-term: torsion=2, fape=0.95\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/rgn2-replica/rgn2_replica/rgn2_trainers.py\u001b[0m in \u001b[0;36mbatched_inference\u001b[0;34m(model, embedder, mode, device, recycle_func, config, *args)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# don't pass angles info - just 0 at start (sin=0, cos=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangles_input\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mangles_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     ], dim=-1)\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got dict"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qovzXcFDPnvC"
      },
      "source": [
        ""
      ]
    }
  ]
}